Loading dataset …
  32033 docs  |  vocab size 27

────────────────────────────────────────────────────────────
  Backend: scalar
────────────────────────────────────────────────────────────
  step     1/3000  |  loss 3.3385  |     51.04 ms
  step   300/3000  |  loss 2.2028  |     45.04 ms
  step   600/3000  |  loss 2.7167  |     57.06 ms
  step   900/3000  |  loss 2.8381  |     39.90 ms
  step  1200/3000  |  loss 1.8778  |     43.97 ms
  step  1500/3000  |  loss 2.1647  |     71.39 ms
  step  1800/3000  |  loss 2.7512  |     40.31 ms
  step  2100/3000  |  loss 2.4067  |     34.91 ms
  step  2400/3000  |  loss 2.7547  |     43.26 ms
  step  2700/3000  |  loss 2.6784  |     32.28 ms
  step  3000/3000  |  loss 2.2548  |     47.51 ms

  Generated names (10 samples, T=0.7):
    kakaria
    kannose
    arees
    hemian
    kyan
    oreya
    aani
    erunn
    kaisel
    sovyan

────────────────────────────────────────────────────────────
  Backend: numpy
────────────────────────────────────────────────────────────
  step     1/3000  |  loss 3.2791  |      0.48 ms
  step   300/3000  |  loss 2.2847  |      0.21 ms
  step   600/3000  |  loss 2.7946  |      0.22 ms
  step   900/3000  |  loss 2.5491  |      0.21 ms
  step  1200/3000  |  loss 2.1884  |      0.22 ms
  step  1500/3000  |  loss 2.2115  |      0.23 ms
  step  1800/3000  |  loss 2.8444  |      0.21 ms
  step  2100/3000  |  loss 2.4800  |      0.21 ms
  step  2400/3000  |  loss 2.7126  |      0.21 ms
  step  2700/3000  |  loss 2.5718  |      0.21 ms
  step  3000/3000  |  loss 2.3142  |      0.22 ms

  Generated names (10 samples, T=0.7):
    easc
    imren
    arah
    trlela
    lame
    arole
    jahaly
    layan
    nalan
    teeva

────────────────────────────────────────────────────────────
  Backend: torch_cpu
────────────────────────────────────────────────────────────
  step     1/3000  |  loss 3.3029  |    208.48 ms
  step   300/3000  |  loss 2.3419  |     37.95 ms
  step   600/3000  |  loss 2.6284  |      0.59 ms
  step   900/3000  |  loss 2.6401  |     41.81 ms
  step  1200/3000  |  loss 1.8730  |      0.56 ms
  step  1500/3000  |  loss 2.1436  |      0.58 ms
  step  1800/3000  |  loss 2.7933  |     45.79 ms
  step  2100/3000  |  loss 2.4827  |      0.58 ms
  step  2400/3000  |  loss 2.7834  |      0.55 ms
  step  2700/3000  |  loss 2.6735  |     45.47 ms
  step  3000/3000  |  loss 2.2469  |     45.59 ms

  Generated names (10 samples, T=0.7):
    guridah
    keazon
    bonge
    alemii
    kaola
    ziicion
    aydii
    kayo
    thyana
    hauneya

────────────────────────────────────────────────────────────
  Backend: torch_gpu
────────────────────────────────────────────────────────────
  step     1/3000  |  loss 3.2877  |    244.35 ms
  step   300/3000  |  loss 2.4096  |      1.82 ms
  step   600/3000  |  loss 2.7958  |      1.85 ms
  step   900/3000  |  loss 2.6918  |      3.99 ms
  step  1200/3000  |  loss 1.9877  |      1.48 ms
  step  1500/3000  |  loss 2.2494  |      1.03 ms
  step  1800/3000  |  loss 2.7063  |      1.51 ms
  step  2100/3000  |  loss 2.3768  |      1.91 ms
  step  2400/3000  |  loss 2.7554  |      1.75 ms
  step  2700/3000  |  loss 2.6265  |      1.85 ms
  step  3000/3000  |  loss 2.2149  |      4.07 ms

  Generated names (10 samples, T=0.7):
    azlaa
    merane
    laale
    lonav
    kemina
    arhe
    dareen
    viosya
    kiveell
    samela

=========================================================================
  BENCHMARK SUMMARY
=========================================================================
Backend         Final Loss   Avg(last100)   Total(s)    Median ms   Speedup
-------------------------------------------------------------------------
  scalar        2.2548       2.3473         156.13      50.71       1.0x
  numpy         2.3142       2.3767         0.66        0.22        237.3x
  torch_cpu     2.2469       2.3570         51.60       0.83        3.0x
  torch_gpu     2.2149       2.3613         5.31        1.81        29.4x
=========================================================================

  Speedup relative to scalar baseline:
    numpy          237.3x  ████████████████████████████████████████████████████████████████████████████████
    torch_cpu        3.0x  ███
    torch_gpu       29.4x  █████████████████████████████

